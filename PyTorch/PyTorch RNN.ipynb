{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyM6YgCoxxTpFz/t5MXmOwYu"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"Jwbwj22jjg7b"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","from torch.utils.data import DataLoader\n","import torchvision.datasets as datasets\n","import torchvision.transforms as transforms\n","from torchsummary import summary"]},{"cell_type":"markdown","source":["Create RNN"],"metadata":{"id":"-b2K8IjN1qCl"}},{"cell_type":"code","source":["# Hyperparameters\n","input_size = 28\n","hidden_size = 256\n","num_layers = 2\n","num_classes = 10\n","sequence_length = 28\n","learning_rate = 0.005\n","batch_size = 64\n","num_epochs = 2\n"],"metadata":{"id":"TPC4RJBO2Tqt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class RNN(nn.Module):\n","    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n","        super(RNN, self).__init__()\n","        self.hidden_size = hidden_size\n","        self.num_layers = num_layers\n","        # input_size = number of features for each time step (input is vector)\n","        # hidden_size = number of nodes in each tme step\n","        # num_layesr = stacking 2 RNNs on top of each other\n","        self.rnn = nn.RNN(input_size, hidden_size, num_layers, batch_first=True)\n","        self.fc = nn.Linear(hidden_size * sequence_length, num_classes)\n","\n","    \n","    def forward(self, x):\n","         # Set initial hidden and cell states\n","        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n","\n","        # Forward propagate LSTM\n","        out, _ = self.rnn(x, h0)\n","        out = out.reshape(out.shape[0], -1)\n","\n","        # Decode the hidden state of the last time step\n","        out = self.fc(out)\n","        return out\n","\n","        return x\n"],"metadata":{"id":"lGdQZ5Cn1tAT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Recurrent neural network with LSTM (many-to-one)\n","class RNN_LSTM(nn.Module):\n","    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n","        super(RNN_LSTM, self).__init__()\n","        self.hidden_size = hidden_size\n","        self.num_layers = num_layers\n","        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n","        self.fc = nn.Linear(hidden_size * sequence_length, num_classes)\n","\n","    def forward(self, x):\n","        # Set initial hidden and cell states\n","        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n","        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n","\n","        # Forward propagate LSTM\n","        out, _ = self.lstm(\n","            x, (h0, c0)\n","        )  # out: tensor of shape (batch_size, seq_length, hidden_size)\n","        out = out.reshape(out.shape[0], -1)\n","\n","        # Decode the hidden state of the last time step\n","        out = self.fc(out)\n","        return out"],"metadata":{"id":"zaSoEEHt596h"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"LkF1FxJb7qft"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Set device"],"metadata":{"id":"N2Iu7rDI635H"}},{"cell_type":"code","source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"],"metadata":{"id":"FiDTVP3C5knv"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Load data"],"metadata":{"id":"SCZgmnsh7TgQ"}},{"cell_type":"code","source":["train_dataset = datasets.MNIST(root='dataset/', train=True, transform = transforms.ToTensor(), download = True )\n","train_loader = DataLoader(dataset = train_dataset, batch_size = batch_size, shuffle = True)\n","\n","test_dataset = datasets.MNIST(\n","    root=\"dataset/\", train=False, transform=transforms.ToTensor(), download=True\n",")\n","test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=True)"],"metadata":{"id":"g-Na3KTc7UjJ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["INitialise data"],"metadata":{"id":"TVYoy9g474P0"}},{"cell_type":"code","source":["model = RNN(input_size, hidden_size, num_layers, num_classes).to(device)\n","print(model)\n","model2 = RNN_LSTM(input_size, hidden_size, num_layers, num_classes).to(device)\n","print(model2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-YpFRxYQ7bSL","executionInfo":{"status":"ok","timestamp":1671697033711,"user_tz":480,"elapsed":166,"user":{"displayName":"Anish Pahilajani","userId":"06270213490194316061"}},"outputId":"bf3c474b-2c86-41da-c004-40996079b9c8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["RNN(\n","  (rnn): RNN(28, 256, num_layers=2, batch_first=True)\n","  (fc): Linear(in_features=7168, out_features=10, bias=True)\n",")\n","RNN_LSTM(\n","  (lstm): LSTM(28, 256, num_layers=2, batch_first=True)\n","  (fc): Linear(in_features=7168, out_features=10, bias=True)\n",")\n"]}]},{"cell_type":"markdown","source":["Loss and optimiser"],"metadata":{"id":"RwIxviOA8xAk"}},{"cell_type":"code","source":["criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model.parameters(), lr = learning_rate)\n","\n","criterionLSTM = nn.CrossEntropyLoss()\n","optimizerLSTM = optim.Adam(model2.parameters(), lr = learning_rate)"],"metadata":{"id":"t7JJIqCo8l-w"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Train netowrk"],"metadata":{"id":"cQVm0VE09J5h"}},{"cell_type":"code","source":["for epoch in range(num_epochs):\n","    for batch_idx, (data, targets) in enumerate(train_loader):\n","        data = data.to(device=device).squeeze(1)\n","        targets = targets.to(device = device)\n","\n","        score = model(data)\n","        loss = criterion(score, targets)\n","\n","        # back prop\n","        optimizer.zero_grad()\n","        loss.backward()\n","\n","        # gradient descent\n","        optimizer.step()\n","\n"],"metadata":{"id":"mfnJrzIb9BI7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for epoch in range(num_epochs):\n","    for batch_idx, (data, targets) in enumerate(train_loader):\n","        data = data.to(device=device).squeeze(1)\n","        targets = targets.to(device = device)\n","\n","        score = model2(data)\n","        loss = criterionLSTM(score, targets)\n","\n","        # back prop\n","        optimizerLSTM.zero_grad()\n","        loss.backward()\n","\n","        # gradient descent\n","        optimizerLSTM.step()\n"],"metadata":{"id":"XWeIitIW6Peu"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Check accuracy"],"metadata":{"id":"GwXL81d_W2BJ"}},{"cell_type":"code","source":["# Check accuracy on training & test to see how good our model\n","def check_accuracy(loader, model):\n","    \"\"\"\n","    Check accuracy of our trained model given a loader and a model\n","    Parameters:\n","        loader: torch.utils.data.DataLoader\n","            A loader for the dataset you want to check accuracy on\n","        model: nn.Module\n","            The model you want to check accuracy on\n","    Returns:\n","        acc: float\n","            The accuracy of the model on the dataset given by the loader\n","    \"\"\"\n","\n","    num_correct = 0\n","    num_samples = 0\n","    model.eval()\n","\n","    # We don't need to keep track of gradients here so we wrap it in torch.no_grad()\n","    with torch.no_grad():\n","        # Loop through the data\n","        for x, y in loader:\n","\n","            # Move data to device\n","            x = x.to(device=device).squeeze(1)\n","            y = y.to(device=device)\n","\n","\n","            # Forward pass\n","            scores = model(x)\n","            _, predictions = scores.max(1)\n","\n","            # Check how many we got correct\n","            num_correct += (predictions == y).sum()\n","\n","            # Keep track of number of samples\n","            num_samples += predictions.size(0)\n","\n","    model.train()\n","    return num_correct / num_samples\n","\n","\n","# Check accuracy on training & test to see how good our model\n","print(f\"Accuracy on training set: {check_accuracy(train_loader, model)*100:.2f}\")\n","print(f\"Accuracy on test set: {check_accuracy(test_loader, model)*100:.2f}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aAKB0scyTu3B","executionInfo":{"status":"ok","timestamp":1671698103578,"user_tz":480,"elapsed":29501,"user":{"displayName":"Anish Pahilajani","userId":"06270213490194316061"}},"outputId":"163b1d75-1383-4afb-a04e-e8885c316843"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy on training set: 9.93\n","Accuracy on test set: 10.32\n"]}]},{"cell_type":"code","source":["# Check accuracy on training & test to see how good our model\n","print(f\"Accuracy on training set: {check_accuracy(train_loader, model2)*100:.2f}\")\n","print(f\"Accuracy on test set: {check_accuracy(test_loader, model2)*100:.2f}\")"],"metadata":{"id":"xV3tEY-xaCKJ","executionInfo":{"status":"ok","timestamp":1671698187141,"user_tz":480,"elapsed":83565,"user":{"displayName":"Anish Pahilajani","userId":"06270213490194316061"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"a27fd40f-7168-4cc3-9344-30a529170df2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy on training set: 98.70\n","Accuracy on test set: 98.47\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"si4-pvEF64Se"},"execution_count":null,"outputs":[]}]}