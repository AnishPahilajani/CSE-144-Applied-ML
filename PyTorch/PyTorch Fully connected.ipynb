{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPHAdfxR4I9NOGh7k45JXlo"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"Jwbwj22jjg7b"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","from torch.utils.data import DataLoader\n","import torchvision.datasets as datasets\n","import torchvision.transforms as transforms\n","from torchsummary import summary"]},{"cell_type":"markdown","source":["Create fully connected netowrk"],"metadata":{"id":"-b2K8IjN1qCl"}},{"cell_type":"code","source":["class NN(nn.Module):\n","    def __init__(self, input_size, num_classes):\n","        super(NN, self).__init__() # call initialisation of the parent class\n","        self.fc1 = nn.Linear(input_size, 50)      # first fully cpnnected neural netowrk\n","        self.fc2 = nn.Linear(50, num_classes)\n","        self.relu = nn.ReLU()\n","    \n","    def forward(self, x):\n","        x = self.relu(self.fc1(x))\n","        x = self.fc2(x)\n","        return x\n"],"metadata":{"id":"lGdQZ5Cn1tAT"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Set device"],"metadata":{"id":"N2Iu7rDI635H"}},{"cell_type":"code","source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"],"metadata":{"id":"FiDTVP3C5knv"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Hyperparameters"],"metadata":{"id":"yWJ0bfTX7Etp"}},{"cell_type":"code","source":["input_size = 784\n","num_classes = 10\n","lr = 0.01\n","batch_size = 64\n","num_epochs = 1"],"metadata":{"id":"IosNpI4N7BCF"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Load data"],"metadata":{"id":"SCZgmnsh7TgQ"}},{"cell_type":"code","source":["train_dataset = datasets.MNIST(root='dataset/', train=True, transform = transforms.ToTensor(), download = True )\n","train_loader = DataLoader(dataset = train_dataset, batch_size = batch_size, shuffle = True)\n","\n","test_dataset = datasets.MNIST(\n","    root=\"dataset/\", train=False, transform=transforms.ToTensor(), download=True\n",")\n","test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=True)"],"metadata":{"id":"g-Na3KTc7UjJ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["INitialise data"],"metadata":{"id":"TVYoy9g474P0"}},{"cell_type":"code","source":["model = NN(input_size = input_size, num_classes = num_classes).to(device)\n","summary(model, (input_size,))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-YpFRxYQ7bSL","executionInfo":{"status":"ok","timestamp":1671671408532,"user_tz":480,"elapsed":4,"user":{"displayName":"Anish Pahilajani","userId":"06270213490194316061"}},"outputId":"d2ab1855-aae9-46d1-dd60-74cdaba007ab"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Linear-1                   [-1, 50]          39,250\n","              ReLU-2                   [-1, 50]               0\n","            Linear-3                   [-1, 10]             510\n","================================================================\n","Total params: 39,760\n","Trainable params: 39,760\n","Non-trainable params: 0\n","----------------------------------------------------------------\n","Input size (MB): 0.00\n","Forward/backward pass size (MB): 0.00\n","Params size (MB): 0.15\n","Estimated Total Size (MB): 0.16\n","----------------------------------------------------------------\n"]}]},{"cell_type":"markdown","source":["Loss and optimiser"],"metadata":{"id":"RwIxviOA8xAk"}},{"cell_type":"code","source":["criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model.parameters(), lr = lr)"],"metadata":{"id":"t7JJIqCo8l-w"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Train netowrk"],"metadata":{"id":"cQVm0VE09J5h"}},{"cell_type":"code","source":["for epoch in range(num_epochs):\n","    for batch_idx, (data, targets) in enumerate(train_loader):\n","        data = data.to(device = device)\n","        targets = targets.to(device = device)\n","\n","        # geet to correct shape\n","        data = data.reshape(data.shape[0], -1)\n","\n","        score = model(data)\n","        loss = crit(score, targets)\n","\n","        # back prop\n","        optimizer.zero_grad()\n","        loss.backward()\n","\n","        # gradient descent\n","        optimizer.step()\n","\n"],"metadata":{"id":"mfnJrzIb9BI7"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Check accuracy"],"metadata":{"id":"GwXL81d_W2BJ"}},{"cell_type":"code","source":["# Check accuracy on training & test to see how good our model\n","def check_accuracy(loader, model):\n","    \"\"\"\n","    Check accuracy of our trained model given a loader and a model\n","    Parameters:\n","        loader: torch.utils.data.DataLoader\n","            A loader for the dataset you want to check accuracy on\n","        model: nn.Module\n","            The model you want to check accuracy on\n","    Returns:\n","        acc: float\n","            The accuracy of the model on the dataset given by the loader\n","    \"\"\"\n","\n","    num_correct = 0\n","    num_samples = 0\n","    model.eval()\n","\n","    # We don't need to keep track of gradients here so we wrap it in torch.no_grad()\n","    with torch.no_grad():\n","        # Loop through the data\n","        for x, y in loader:\n","\n","            # Move data to device\n","            x = x.to(device=device)\n","            y = y.to(device=device)\n","\n","            # Get to correct shape\n","            x = x.reshape(x.shape[0], -1)\n","\n","            # Forward pass\n","            scores = model(x)\n","            _, predictions = scores.max(1)\n","\n","            # Check how many we got correct\n","            num_correct += (predictions == y).sum()\n","\n","            # Keep track of number of samples\n","            num_samples += predictions.size(0)\n","\n","    model.train()\n","    return num_correct / num_samples\n","\n","\n","# Check accuracy on training & test to see how good our model\n","print(f\"Accuracy on training set: {check_accuracy(train_loader, model)*100:.2f}\")\n","print(f\"Accuracy on test set: {check_accuracy(test_loader, model)*100:.2f}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aAKB0scyTu3B","executionInfo":{"status":"ok","timestamp":1671671426291,"user_tz":480,"elapsed":7540,"user":{"displayName":"Anish Pahilajani","userId":"06270213490194316061"}},"outputId":"b5379578-6ea0-4a97-8a47-a0828d21a9bb"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy on training set: 95.66\n","Accuracy on test set: 95.29\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"2F-eCdPVW3nf","executionInfo":{"status":"ok","timestamp":1671671974030,"user_tz":480,"elapsed":174,"user":{"displayName":"Anish Pahilajani","userId":"06270213490194316061"}}},"execution_count":65,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"XQjwYeoMaP1f"},"execution_count":null,"outputs":[]}]}